"""
Agent RAG Studio - Main Streamlit Application
"""
import streamlit as st
import os
import logging
from pathlib import Path
import traceback

# ç’°å¢ƒå¤‰æ•°ã‚’ç¢ºå®Ÿã«ç„¡åŠ¹åŒ–ï¼ˆè­¦å‘Šåœæ­¢ã®ãŸã‚ï¼‰
os.environ['LANGCHAIN_TRACING_V2'] = 'false'
os.environ['LANGCHAIN_ENDPOINT'] = ''
os.environ['LANGCHAIN_API_KEY'] = ''
os.environ['LANGSMITH_ENABLED'] = 'false'
os.environ['COHERE_API_KEY'] = ''

# Resolve a writable log directory (Streamlit Cloud mounts /mount/src as read-only)
def _resolve_log_dir() -> Path:
    # 1) Explicit env var
    env_dir = os.getenv('STREAMLIT_LOG_DIR')
    if env_dir:
        p = Path(env_dir)
        try:
            p.mkdir(parents=True, exist_ok=True)
            return p
        except Exception:
            pass
    # 2) Streamlit Cloud writable mount
    mount_data = Path('/mount/data')
    if mount_data.exists():
        p = mount_data / 'logs'
        try:
            p.mkdir(parents=True, exist_ok=True)
            return p
        except Exception:
            pass
    # 3) Fallback to local relative path
    p = Path('logs')
    p.mkdir(parents=True, exist_ok=True)
    return p

LOG_DIR = _resolve_log_dir()

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(str(LOG_DIR / 'app.log'), encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# Set page config
st.set_page_config(
    page_title="Agent RAG Studio",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Import our modules
try:
    from rag.config import get_config, update_config
    from rag.loader import DocumentLoader, DocumentStats
    from rag.splitter import get_splitter, analyze_chunks
    from rag.embedder import get_embedding_manager
    from rag.store import get_vector_store
    from rag.retriever import create_retriever, create_reranking_retriever
    from rag.chain import create_rag_chain, create_conversational_rag_chain
except ImportError as e:
    st.error(f"ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    st.stop()

def initialize_session_state():
    """Initialize Streamlit session state"""
    if 'initialized' not in st.session_state:
        st.session_state.initialized = True
        st.session_state.config = get_config()
        st.session_state.messages = []
        st.session_state.documents = []
        st.session_state.chunks = []
        st.session_state.vector_store = None
        st.session_state.retriever = None
        st.session_state.chain = None
        st.session_state.index_ready = False
        st.session_state.stats = {}
        
        # Create necessary directories
        os.makedirs("data", exist_ok=True)
        os.makedirs("logs", exist_ok=True)

def render_sidebar():
    """Render sidebar with configuration options"""
    with st.sidebar:
        st.title("ğŸ¤– Agent RAG Studio")
        st.markdown("---")
        
        # API Key Status
        st.subheader("ğŸ”‘ APIè¨­å®šçŠ¶æ³")
        config = st.session_state.config
        key_status = config.validate_keys()
        
        for service, status in key_status.items():
            icon = "âœ…" if status else "âŒ"
            st.write(f"{icon} {service.upper()}: {'è¨­å®šæ¸ˆã¿' if status else 'æœªè¨­å®š'}")
        
        if not any(key_status.values()):
            demo_mode = config.__dict__.get('demo_mode', False)
            if demo_mode:
                st.info("ğŸ”§ ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ï¼šãƒ­ãƒ¼ã‚«ãƒ«åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼ˆOpenAI APIã‚­ãƒ¼ä¸è¦ï¼‰")
            else:
                st.warning("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.streamlit/secrets.toml ã¾ãŸã¯ .env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        st.markdown("---")
        
        # RAG Configuration
        st.subheader("âš™ï¸ RAGè¨­å®š")
        
        # Model selection
        embedding_models = [
            "sentence-transformers/all-MiniLM-L6-v2",
            "sentence-transformers/all-mpnet-base-v2",
            "text-embedding-3-small",
            "text-embedding-3-large"
        ]
        
        embedding_model = st.selectbox(
            "åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«",
            embedding_models,
            index=embedding_models.index(config.embedding_model) if config.embedding_model in embedding_models else 0
        )
        
        llm_model = "gpt-4o-mini"  # å›ºå®šãƒ¢ãƒ‡ãƒ«
        
        # Vector store selection
        vector_store_type = st.selectbox(
            "ãƒ™ã‚¯ã‚¿ã‚¹ãƒˆã‚¢",
            ["chroma", "faiss"],
            index=0 if config.vector_store == "chroma" else 1
        )
        
        # Generation parameters
        st.subheader("ğŸ“ ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
        
        temperature = st.slider(
            "Temperature",
            min_value=0.0,
            max_value=1.0,
            value=config.temperature,
            step=0.05,
            help="ç”Ÿæˆã®å‰µé€ æ€§ã‚’åˆ¶å¾¡ï¼ˆ0=æ±ºå®šçš„ã€1=å‰µé€ çš„ï¼‰"
        )
        
        max_tokens = st.slider(
            "æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°",
            min_value=100,
            max_value=2000,
            value=config.max_tokens,
            step=100,
            help="ç”Ÿæˆã™ã‚‹æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°"
        )
        
        # Retrieval parameters
        st.subheader("ğŸ” æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
        
        top_k = st.slider(
            "Top-K",
            min_value=1,
            max_value=20,
            value=config.top_k,
            help="æ¤œç´¢ã™ã‚‹æ–‡æ›¸æ•°"
        )
        
        # Disable reranking toggle if no Cohere key
        use_reranking = st.toggle(
            "Cohere Rerankä½¿ç”¨",
            value=config.use_reranking,
            help="Cohere Rerankã§æ¤œç´¢çµæœã‚’å†é †ä½ä»˜ã‘",
            disabled=not bool(config.cohere_api_key)
        )
        
        rerank_top_r = st.slider(
            "Rerank Top-R",
            min_value=1,
            max_value=10,
            value=config.rerank_top_r,
            help="å†é †ä½ä»˜ã‘å¾Œã®æ–‡æ›¸æ•°",
            disabled=not use_reranking
        )
        
        # LangSmith tracing
        st.subheader("ğŸªª ãƒ­ã‚°/ãƒˆãƒ¬ãƒ¼ã‚¹")
        langsmith_enabled = st.toggle(
            "LangSmith ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’æœ‰åŠ¹åŒ–",
            value=config.__dict__.get('langsmith_enabled', False),
            help="LangSmithã§å®Ÿè¡Œãƒˆãƒ¬ãƒ¼ã‚¹ã‚’åé›†ï¼ˆAPIã‚­ãƒ¼ãŒå¿…è¦ï¼‰"
        )

        # Update configuration
        if st.button("è¨­å®šã‚’æ›´æ–°"):
            update_config(
                embedding_model=embedding_model,
                default_llm=llm_model,
                vector_store=vector_store_type,
                temperature=temperature,
                max_tokens=max_tokens,
                top_k=top_k,
                rerank_top_r=rerank_top_r,
                use_reranking=use_reranking,
                langsmith_enabled=langsmith_enabled,
            )
            st.session_state.config = get_config()
            st.rerun()
        
        st.markdown("---")
        
        # Index Status
        st.subheader("ğŸ“Š ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çŠ¶æ³")
        if st.session_state.index_ready:
            st.success("âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æº–å‚™å®Œäº†")
            
            if st.session_state.stats:
                stats = st.session_state.stats
                st.write(f"ğŸ“„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {stats.get('total_documents', 0)}")
                st.write(f"ğŸ“ ãƒãƒ£ãƒ³ã‚¯æ•°: {stats.get('total_chunks', 0)}")
                st.write(f"ğŸ’¾ ãƒ™ã‚¯ã‚¿ã‚¹ãƒˆã‚¢: {stats.get('vector_store_type', 'unknown')}")
        else:
            st.warning("âš ï¸ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœªä½œæˆ")
            st.write("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†ãƒšãƒ¼ã‚¸ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")

def main():
    """Main application function"""
    initialize_session_state()
    render_sidebar()
    
    # Main content area
    st.title("ğŸ¤– Agent RAG Studio")
    st.markdown("**é«˜ç²¾åº¦ RAG + ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹ QA ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³**")
    
    # Quick Start Guide
    if not st.session_state.index_ready:
        st.info("**ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¬ã‚¤ãƒ‰**")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("""
            **1ï¸âƒ£ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæº–å‚™**
            - ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã€Œãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†ã€ãƒšãƒ¼ã‚¸ã«ç§»å‹•
            - PDFã€Markdownã€HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            - ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
            """)
        
        with col2:
            st.markdown("""
            **2ï¸âƒ£ ãƒãƒ£ãƒƒãƒˆé–‹å§‹**
            - ã€Œãƒãƒ£ãƒƒãƒˆã€ãƒšãƒ¼ã‚¸ã§è³ªå•ã‚’å…¥åŠ›
            - AIãŒé–¢é€£æ–‡æ›¸ã‚’æ¤œç´¢ã—ã¦å›ç­”
            - å¼•ç”¨ä»˜ãã§æ­£ç¢ºãªæƒ…å ±ã‚’æä¾›
            """)
        
        with col3:
            st.markdown("""
            **3ï¸âƒ£ è©•ä¾¡ãƒ»æ”¹å–„**
            - ã€Œè©•ä¾¡ã€ãƒšãƒ¼ã‚¸ã§ã‚·ã‚¹ãƒ†ãƒ æ€§èƒ½ã‚’ç¢ºèª
            - Ragasã«ã‚ˆã‚‹è‡ªå‹•è©•ä¾¡
            - å›ç­”å“è³ªã®ç¶™ç¶šçš„æ”¹å–„
            """)
    
    else:
        # Quick chat interface for the main page
        st.subheader("ğŸ’¬ ã‚¯ã‚¤ãƒƒã‚¯ãƒãƒ£ãƒƒãƒˆ")
        st.markdown("ã“ã“ã§ç°¡å˜ãªè³ªå•ãŒã§ãã¾ã™ã€‚è©³ç´°ãªãƒãƒ£ãƒƒãƒˆã¯ã€Œãƒãƒ£ãƒƒãƒˆã€ãƒšãƒ¼ã‚¸ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚")
        
        # Chat input
        user_input = st.text_input(
            "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:",
            placeholder="ä¾‹: LangChainã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
            key="quick_chat_input"
        )
        
        col1, col2 = st.columns([1, 4])
        with col1:
            if st.button("é€ä¿¡", type="primary", disabled=not user_input):
                if st.session_state.chain:
                    with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
                        try:
                            result = st.session_state.chain.invoke({"question": user_input})
                            
                            st.markdown("### å›ç­”")
                            st.markdown(result["answer"])
                            
                            if result.get("sources"):
                                with st.expander("ğŸ“š å‚ç…§ã‚½ãƒ¼ã‚¹"):
                                    for source in result["sources"]:
                                        st.markdown(f"""
                                        **{source.get('title', 'Untitled')}**  
                                        ğŸ“ {source.get('file_name', 'Unknown')}  
                                        ğŸ“„ ãƒšãƒ¼ã‚¸: {source.get('page', 'N/A')}  
                                        ğŸ“Š ã‚¹ã‚³ã‚¢: {source.get('score', 0.0):.3f}  
                                        
                                        {source.get('snippet', '')}
                                        """)
                            
                            st.success(f"â±ï¸ å¿œç­”æ™‚é–“: {result.get('latency', 0):.2f}ç§’")
                            
                        except Exception as e:
                            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                            logger.error(f"Quick chat error: {e}")
                            logger.error(traceback.format_exc())
                else:
                    st.error("ãƒã‚§ãƒ¼ãƒ³ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã¾ãšã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
    
    # Status and Statistics
    if st.session_state.index_ready:
        st.markdown("---")
        st.subheader("ğŸ“ˆ ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³")
        
        col1, col2, col3, col4 = st.columns(4)
        
        stats = st.session_state.stats
        
        with col1:
            st.metric(
                "ğŸ“„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°",
                stats.get('total_documents', 0)
            )
        
        with col2:
            st.metric(
                "ğŸ“ ãƒãƒ£ãƒ³ã‚¯æ•°", 
                stats.get('total_chunks', 0)
            )
        
        with col3:
            st.metric(
                "ğŸ¤– ãƒ¢ãƒ‡ãƒ«",
                st.session_state.config.default_llm
            )
        
        with col4:
            st.metric(
                "ğŸ’¾ ãƒ™ã‚¯ã‚¿ã‚¹ãƒˆã‚¢",
                st.session_state.config.vector_store.upper()
            )
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666;'>
        <p>Agent RAG Studio v1.0 | 
        <a href='https://github.com/your-repo' target='_blank'>GitHub</a> | 
        <a href='https://docs.your-site.com' target='_blank'>ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ</a>
        </p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        st.error(f"ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"Application error: {e}")
        logger.error(traceback.format_exc())
        
        # Show debug information in development
        if os.getenv("STREAMLIT_ENV") == "development":
            st.exception(e)
