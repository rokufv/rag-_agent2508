"""
Chat Interface Page for Agent RAG Studio
"""
import streamlit as st
import logging
from datetime import datetime
import json
import traceback
from typing import Dict, Any, List

# Configure logging
logger = logging.getLogger(__name__)

# Import our modules
try:
    from rag.config import get_config
    from rag.chain import create_conversational_rag_chain
except ImportError as e:
    st.error(f"ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    st.stop()

def initialize_session_state():
    """Initialize session state for chat"""
    if 'chat_initialized' not in st.session_state:
        st.session_state.chat_initialized = True
        st.session_state.messages = []
        st.session_state.conversation_chain = None
        # å‡ºåŠ›å½¢å¼ã®æ—¢å®š
        if 'output_format' not in st.session_state:
            st.session_state.output_format = 'markdown'
        st.session_state.chat_stats = {
            'total_queries': 0,
            'total_tokens': 0,
            'average_response_time': 0.0,
            'session_start': datetime.now().isoformat()
        }

def create_conversation_chain():
    """Create or recreate the conversation chain"""
    if st.session_state.get('chain') and st.session_state.get('retriever'):
        try:
            conv_chain = create_conversational_rag_chain(
                retriever=st.session_state.retriever,
                llm_model=st.session_state.config.default_llm,
                temperature=st.session_state.config.temperature,
                max_tokens=st.session_state.config.max_tokens,
                use_reranking=st.session_state.config.use_reranking,
                rerank_top_k=st.session_state.config.rerank_top_r,
                output_format=st.session_state.get('output_format', 'markdown')
            )
            st.session_state.conversation_chain = conv_chain
            return True
        except Exception as e:
            logger.error(f"Error creating conversation chain: {e}")
            return False
    return False

def render_chat_interface():
    """Render the main chat interface"""
    if not st.session_state.get('index_ready', False):
        st.warning("âš ï¸ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒä½œæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
        st.info("ã€Œãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†ã€ãƒšãƒ¼ã‚¸ã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
        return
    
    # Create conversation chain if not exists
    if not st.session_state.conversation_chain:
        if not create_conversation_chain():
            st.error("ä¼šè©±ãƒã‚§ãƒ¼ãƒ³ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return
    
    # Chat configuration sidebar
    with st.sidebar:
        st.subheader("ğŸ’¬ ãƒãƒ£ãƒƒãƒˆè¨­å®š")
        
        # å‡ºåŠ›å½¢å¼ï¼ˆãƒã‚§ãƒ¼ãƒ³ã«åæ˜ ï¼‰
        prev_format = st.session_state.get('output_format', 'markdown')
        output_format = st.selectbox(
            "å›ç­”å½¢å¼",
            ["markdown", "json"],
            index=(0 if prev_format == 'markdown' else 1),
            help="å›ç­”ã®å‡ºåŠ›å½¢å¼ã‚’é¸æŠ"
        )
        if output_format != prev_format:
            st.session_state.output_format = output_format
            # å½¢å¼å¤‰æ›´æ™‚ã¯ä¼šè©±ãƒã‚§ãƒ¼ãƒ³ã‚’ä½œã‚Šç›´ã™
            st.session_state.conversation_chain = None
            create_conversation_chain()
        
        # Conversation mode
        conversation_mode = st.toggle(
            "ä¼šè©±å±¥æ­´ã‚’è€ƒæ…®",
            value=True,
            help="å‰ã®è³ªå•ãƒ»å›ç­”ã‚’æ–‡è„ˆã¨ã—ã¦è€ƒæ…®"
        )
        
        # Advanced settings
        with st.expander("âš™ï¸ è©³ç´°è¨­å®š"):
            show_sources = st.toggle("ã‚½ãƒ¼ã‚¹è¡¨ç¤º", value=True)
            show_confidence = st.toggle("ä¿¡é ¼åº¦è¡¨ç¤º", value=True)
            show_metadata = st.toggle("ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º", value=False)
            auto_scroll = st.toggle("è‡ªå‹•ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«", value=True)
        
        # Session statistics
        st.subheader("ğŸ“Š ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆ")
        stats = st.session_state.chat_stats
        st.metric("è³ªå•æ•°", stats['total_queries'])
        st.metric("å¹³å‡å¿œç­”æ™‚é–“", f"{stats['average_response_time']:.2f}s")
        
        # Clear chat button
        if st.button("ğŸ—‘ï¸ ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
            st.session_state.messages = []
            if st.session_state.conversation_chain:
                st.session_state.conversation_chain.clear_history()
            st.session_state.chat_stats['total_queries'] = 0
            st.rerun()
    
    # Display chat messages
    chat_container = st.container()
    
    with chat_container:
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                if message["role"] == "user":
                    st.write(message["content"])
                else:
                    # Display assistant response
                    st.markdown(message["content"])
                    
                    # Display sources if available
                    if show_sources and message.get("sources"):
                        with st.expander("ğŸ“š å‚ç…§ã‚½ãƒ¼ã‚¹"):
                            for i, source in enumerate(message["sources"], 1):
                                col1, col2 = st.columns([3, 1])
                                
                                with col1:
                                    st.markdown(f"""
                                    **[{i}] {source.get('title', 'Untitled')}**  
                                    ğŸ“ {source.get('file_name', 'Unknown')}  
                                    ğŸ“„ ãƒšãƒ¼ã‚¸: {source.get('page', 'N/A')}
                                    """)
                                    
                                    if source.get('snippet'):
                                        st.text(source['snippet'])
                                
                                with col2:
                                    if show_confidence:
                                        score = source.get('score', 0.0)
                                        st.metric("ã‚¹ã‚³ã‚¢", f"{score:.3f}")
                                    
                                    if show_metadata and source.get('metadata'):
                                        with st.expander("è©³ç´°"):
                                            st.json(source['metadata'], expanded=False)
                    
                    # Display metadata if enabled
                    if show_metadata and message.get("metadata"):
                        with st.expander("ğŸ” ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿"):
                            st.json(message["metadata"], expanded=False)

def process_user_input(user_input: str):
    """Process user input and generate response"""
    if not user_input.strip():
        return
    
    # Add user message to chat
    st.session_state.messages.append({
        "role": "user",
        "content": user_input,
        "timestamp": datetime.now().isoformat()
    })
    
    # Generate response
    with st.chat_message("assistant"):
        with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
            try:
                # Use conversation chain if available
                if st.session_state.conversation_chain:
                    result = st.session_state.conversation_chain.invoke({"question": user_input})
                else:
                    result = st.session_state.chain.invoke({"question": user_input})

                if not result or not isinstance(result, dict) or "answer" not in result:
                    st.error("AIã‹ã‚‰æœ‰åŠ¹ãªå›ç­”ãŒè¿”ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ã”é€£çµ¡ãã ã•ã„ã€‚")
                    return

                # Display response
                st.markdown(result["answer"])
                
                # Display sources
                if result.get("sources"):
                    with st.expander("ğŸ“š å‚ç…§ã‚½ãƒ¼ã‚¹"):
                        for i, source in enumerate(result["sources"], 1):
                            st.markdown(f"""
                            **[{i}] {source.get('title', 'Untitled')}**  
                            ğŸ“ {source.get('file_name', 'Unknown')}  
                            ğŸ“„ ãƒšãƒ¼ã‚¸: {source.get('page', 'N/A')}  
                            ğŸ“Š ã‚¹ã‚³ã‚¢: {source.get('score', 0.0):.3f}
                            
                            {source.get('snippet', '')}
                            """)
                
                # Display response metadata
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.success(f"â±ï¸ {result.get('latency', 0):.2f}ç§’")
                with col2:
                    st.info(f"ğŸ¤– {st.session_state.config.default_llm}")
                with col3:
                    if result.get('confidence'):
                        st.metric("ä¿¡é ¼åº¦", f"{result['confidence']:.2f}")
                
                # Add assistant message to chat
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": result["answer"],
                    "sources": result.get("sources", []),
                    "metadata": {
                        "latency": result.get("latency", 0),
                        "model": st.session_state.config.default_llm,
                        "confidence": result.get("confidence"),
                        "timestamp": result.get("timestamp"),
                    },
                    "timestamp": datetime.now().isoformat()
                })
                
                # Update statistics
                stats = st.session_state.chat_stats
                stats['total_queries'] += 1
                
                # Update average response time
                if stats['total_queries'] == 1:
                    stats['average_response_time'] = result.get('latency', 0)
                else:
                    current_avg = stats['average_response_time']
                    new_time = result.get('latency', 0)
                    stats['average_response_time'] = (current_avg * (stats['total_queries'] - 1) + new_time) / stats['total_queries']
                
            except Exception as e:
                error_message = f"ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
                st.error(error_message)
                
                # Add error message to chat
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": error_message,
                    "sources": [],
                    "metadata": {"error": str(e)},
                    "timestamp": datetime.now().isoformat()
                })
                
                logger.error(f"Chat error: {e}")
                logger.error(traceback.format_exc())

def render_suggested_questions():
    """Render suggested questions section"""
    st.subheader("ğŸ’¡ è³ªå•ä¾‹")
    
    suggested_questions = [
        "LangChainã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "RAGã‚·ã‚¹ãƒ†ãƒ ã®ä»•çµ„ã¿ã‚’æ•™ãˆã¦ãã ã•ã„",
        "ãƒ™ã‚¯ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆ©ç‚¹ã¯ï¼Ÿ",
        "ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ©Ÿèƒ½ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ãã ã•ã„",
        "LangGraphã®ç‰¹å¾´ã¯ï¼Ÿ",
        "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã¯ï¼Ÿ"
    ]
    
    cols = st.columns(2)
    for i, question in enumerate(suggested_questions):
        col = cols[i % 2]
        with col:
            if st.button(question, key=f"suggested_{i}"):
                # Set the question in the input (this is a workaround since we can't directly modify chat input)
                st.session_state.suggested_question = question
                st.rerun()

def render_export_section():
    """Render chat export section"""
    if not st.session_state.messages:
        return
    
    with st.expander("ğŸ“¤ ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"):
        # Export as JSON
        chat_data = {
            "session_info": st.session_state.chat_stats,
            "messages": st.session_state.messages,
            "exported_at": datetime.now().isoformat()
        }
        
        json_str = json.dumps(chat_data, ensure_ascii=False, indent=2)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.download_button(
                label="ğŸ“„ JSONã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=json_str,
                file_name=f"chat_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )
        
        with col2:
            # Export as markdown
            markdown_content = "# ãƒãƒ£ãƒƒãƒˆå±¥æ­´\n\n"
            for message in st.session_state.messages:
                role = "ğŸ§‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼" if message["role"] == "user" else "ğŸ¤– ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ"
                markdown_content += f"## {role}\n\n{message['content']}\n\n"
                
                if message.get("sources"):
                    markdown_content += "### å‚ç…§ã‚½ãƒ¼ã‚¹\n\n"
                    for i, source in enumerate(message["sources"], 1):
                        markdown_content += f"{i}. {source.get('title', 'Untitled')} ({source.get('file_name', 'Unknown')})\n"
                    markdown_content += "\n"
            
            st.download_button(
                label="ğŸ“ Markdownã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=markdown_content,
                file_name=f"chat_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                mime="text/markdown"
            )

def main():
    """Main function for the Chat page"""
    st.set_page_config(
        page_title="Chat - Agent RAG Studio",
        page_icon="ğŸ’¬",
        layout="wide"
    )
    
    initialize_session_state()
    
    st.title("ğŸ’¬ ãƒãƒ£ãƒƒãƒˆ")
    st.markdown("AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¨å¯¾è©±ã—ã¦ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å†…å®¹ã«ã¤ã„ã¦è³ªå•ã§ãã¾ã™")
    
    # Check if system is ready
    if not st.session_state.get('index_ready', False):
        st.warning("âš ï¸ ã‚·ã‚¹ãƒ†ãƒ ãŒæº–å‚™ã§ãã¦ã„ã¾ã›ã‚“")
        st.info("ã€Œãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†ã€ãƒšãƒ¼ã‚¸ã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
        
        # Show suggested questions anyway
        render_suggested_questions()
        return
    
    # Main chat interface
    render_chat_interface()
    
    # Chat input
    user_input = st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...")
    
    # Handle suggested question
    if st.session_state.get('suggested_question'):
        user_input = st.session_state.suggested_question
        del st.session_state.suggested_question
    
    # Process user input
    if user_input:
        process_user_input(user_input)
        st.rerun()
    
    # Show suggested questions if no messages yet
    if not st.session_state.messages:
        render_suggested_questions()
    else:
        # Show export options
        render_export_section()

if __name__ == "__main__":
    main()
