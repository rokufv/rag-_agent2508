"""
Document Management Page for Agent RAG Studio
"""
import streamlit as st
import os
import logging
from pathlib import Path
import traceback
from typing import List
import time

# Configure logging
logger = logging.getLogger(__name__)

# Import our modules
try:
    from rag.config import get_config
    from rag.loader import DocumentLoader, DocumentStats
    from rag.splitter import get_splitter, analyze_chunks
    from rag.embedder import get_embedding_manager
    from rag.store import get_vector_store
    from rag.retriever import create_retriever
    from rag.chain import create_rag_chain
except ImportError as e:
    st.error(f"ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    st.stop()

def initialize_session_state():
    """Initialize session state if not already done"""
    if 'initialized' not in st.session_state:
        st.session_state.initialized = True
        st.session_state.config = get_config()
        st.session_state.documents = []
        st.session_state.chunks = []
        st.session_state.vector_store = None
        st.session_state.retriever = None
        st.session_state.chain = None
        st.session_state.index_ready = False
        st.session_state.stats = {}

def render_upload_section():
    """Render file upload section"""
    st.subheader("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    
    # Supported file types
    supported_types = DocumentLoader.get_supported_extensions()
    st.info(f"**ã‚µãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼:** {', '.join(supported_types)}")
    
    # File uploader
    uploaded_files = st.file_uploader(
        "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„",
        type=[ext.replace('.', '') for ext in supported_types],
        accept_multiple_files=True,
        help="è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åŒæ™‚ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™"
    )
    
    if uploaded_files:
        st.success(f"âœ… {len(uploaded_files)} ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¾ã—ãŸ")
        
        # Show file details
        with st.expander("ğŸ“‹ ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°"):
            for file in uploaded_files:
                file_size = len(file.getbuffer()) / 1024 / 1024  # MB
                st.write(f"ğŸ“„ **{file.name}** ({file_size:.2f} MB)")
        
        # Load documents button
        if st.button("ğŸ“– ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿", type="primary"):
            with st.spinner("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿ä¸­..."):
                try:
                    # Create data directory
                    data_dir = Path("data")
                    data_dir.mkdir(exist_ok=True)
                    
                    # Load documents
                    all_documents = []
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    for i, uploaded_file in enumerate(uploaded_files):
                        status_text.text(f"èª­ã¿è¾¼ã¿ä¸­: {uploaded_file.name}")
                        
                        # Load document
                        docs = DocumentLoader.load_uploaded_file(
                            uploaded_file, 
                            save_dir=str(data_dir)
                        )
                        all_documents.extend(docs)
                        
                        # Update progress
                        progress = (i + 1) / len(uploaded_files)
                        progress_bar.progress(progress)
                    
                    # Store in session state
                    st.session_state.documents = all_documents
                    
                    # Calculate statistics
                    stats = DocumentStats.analyze_documents(all_documents)
                    st.session_state.stats.update(stats)
                    
                    progress_bar.empty()
                    status_text.empty()
                    
                    st.success(f"âœ… {len(all_documents)} ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                    
                    # Display statistics
                    st.markdown(DocumentStats.format_stats_for_display(stats))
                    
                except Exception as e:
                    st.error(f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    logger.error(f"Document loading error: {e}")
                    logger.error(traceback.format_exc())

def render_chunking_section():
    """Render document chunking configuration"""
    if not st.session_state.documents:
        st.info("ã¾ãšãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
        return
    
    st.subheader("âœ‚ï¸ ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²è¨­å®š")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Splitting strategy
        strategy = st.selectbox(
            "åˆ†å‰²æˆ¦ç•¥",
            ["recursive", "token", "markdown", "html"],
            help="ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²ã®æ–¹æ³•ã‚’é¸æŠ"
        )
        
        # Chunk size
        chunk_size = st.slider(
            "ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º",
            min_value=200,
            max_value=2000,
            value=1000,
            step=100,
            help="å„ãƒãƒ£ãƒ³ã‚¯ã®æœ€å¤§æ–‡å­—æ•°"
        )
    
    with col2:
        # Chunk overlap
        chunk_overlap = st.slider(
            "ãƒãƒ£ãƒ³ã‚¯ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—",
            min_value=0,
            max_value=500,
            value=100,
            step=50,
            help="éš£æ¥ãƒãƒ£ãƒ³ã‚¯é–“ã®é‡è¤‡æ–‡å­—æ•°"
        )
    
    # Split documents button
    if st.button("âœ‚ï¸ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’åˆ†å‰²", type="primary"):
        with st.spinner("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’åˆ†å‰²ä¸­..."):
            try:
                # Create splitter
                splitter = get_splitter(
                    strategy=strategy,
                    chunk_size=chunk_size,
                    chunk_overlap=chunk_overlap
                )
                
                # Split documents
                chunks = splitter.split_documents(st.session_state.documents)
                st.session_state.chunks = chunks
                
                # Analyze chunks
                chunk_stats = analyze_chunks(chunks)
                st.session_state.stats.update(chunk_stats)
                
                st.success(f"âœ… {len(chunks)} ãƒãƒ£ãƒ³ã‚¯ã‚’ä½œæˆã—ã¾ã—ãŸ")
                
                # Display chunk statistics
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("ç·ãƒãƒ£ãƒ³ã‚¯æ•°", chunk_stats['total_chunks'])
                
                with col2:
                    st.metric("å¹³å‡ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º", f"{chunk_stats.get('average_chunk_size', 0):.0f}")
                
                with col3:
                    st.metric("æœ€å°/æœ€å¤§ã‚µã‚¤ã‚º", f"{chunk_stats.get('min_chunk_size', 0)}/{chunk_stats.get('max_chunk_size', 0)}")
                
                with col4:
                    st.metric("æ¨å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°", f"{chunk_stats.get('total_tokens_estimate', 0):,}")
                
                # Show sample chunks
                with st.expander("ğŸ“ ãƒãƒ£ãƒ³ã‚¯ã‚µãƒ³ãƒ—ãƒ«"):
                    for i, chunk in enumerate(chunks[:3]):
                        st.markdown(f"**ãƒãƒ£ãƒ³ã‚¯ {i+1}:**")
                        st.text(chunk.page_content[:200] + "..." if len(chunk.page_content) > 200 else chunk.page_content)
                        st.json(chunk.metadata, expanded=False)
                        st.markdown("---")
                
            except Exception as e:
                st.error(f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåˆ†å‰²ã‚¨ãƒ©ãƒ¼: {str(e)}")
                logger.error(f"Document splitting error: {e}")
                logger.error(traceback.format_exc())

def render_indexing_section():
    """Render vector indexing section"""
    if not st.session_state.chunks:
        st.info("ã¾ãšãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’åˆ†å‰²ã—ã¦ãã ã•ã„")
        return
    
    st.subheader("ğŸš€ ãƒ™ã‚¯ã‚¿ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Embedding model selection
        embedding_models = [
            "text-embedding-3-small",
            "text-embedding-3-large",
            "sentence-transformers/all-MiniLM-L6-v2",
            "sentence-transformers/all-mpnet-base-v2"
        ]
        
        embedding_model = st.selectbox(
            "åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«",
            embedding_models,
            index=0
        )
    
    with col2:
        # Vector Store Selection
        vector_store = st.selectbox(
            "ğŸ—„ï¸ ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢",
            ["faiss", "chroma"],  # FAISS first
            index=0 if st.session_state.config.vector_store == "faiss" else 1
        )
    
    # Create index button
    if st.button("ğŸš€ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ", type="primary"):
        with st.spinner("ãƒ™ã‚¯ã‚¿ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆä¸­..."):
            try:
                # Initialize embedding manager
                embedding_manager = get_embedding_manager(embedding_model)
                
                # Initialize vector store
                vector_store_manager = get_vector_store(
                    store_type=vector_store,
                    embedding_manager=embedding_manager
                )
                
                # Clear existing store if any
                if st.checkbox("æ—¢å­˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ã‚¯ãƒªã‚¢", value=False):
                    vector_store_manager.clear()
                
                # Create progress tracking
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                def progress_callback(progress, message):
                    progress_bar.progress(progress)
                    status_text.text(message)
                
                # Add documents to vector store
                doc_ids = vector_store_manager.add_documents(
                    st.session_state.chunks,
                    batch_size=50,
                    progress_callback=progress_callback
                )
                
                # Create retriever
                retriever = create_retriever(
                    vector_store_manager=vector_store_manager,
                    documents=st.session_state.chunks,
                    retriever_type="hybrid"
                )
                
                # Create RAG chain
                chain = create_rag_chain(
                    retriever=retriever,
                    llm_model=st.session_state.config.default_llm,
                    temperature=st.session_state.config.temperature,
                    max_tokens=st.session_state.config.max_tokens,
                    use_reranking=st.session_state.config.use_reranking,
                    rerank_top_k=st.session_state.config.rerank_top_r,
                    output_format=st.session_state.get('output_format', 'markdown')
                )
                
                # Store in session state
                st.session_state.vector_store = vector_store_manager
                st.session_state.retriever = retriever
                st.session_state.chain = chain
                st.session_state.index_ready = True
                
                # Update stats
                vector_stats = vector_store_manager.get_stats()
                st.session_state.stats.update({
                    'vector_store_type': vector_store,
                    'embedding_model': embedding_model,
                    'vector_store_stats': vector_stats
                })
                
                progress_bar.empty()
                status_text.empty()
                
                st.success(f"âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒæ­£å¸¸ã«ä½œæˆã•ã‚Œã¾ã—ãŸï¼")
                st.balloons()
                
                # Display final statistics
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ¸ˆã¿æ–‡æ›¸", len(doc_ids))
                
                with col2:
                    st.metric("ãƒ™ã‚¯ã‚¿ã‚¹ãƒˆã‚¢", vector_store.upper())
                
                with col3:
                    st.metric("åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«", embedding_model.split('/')[-1])
                
                st.info("ğŸ‰ ã“ã‚Œã§ã€Œãƒãƒ£ãƒƒãƒˆã€ãƒšãƒ¼ã‚¸ã§è³ªå•ã‚’é–‹å§‹ã§ãã¾ã™ï¼")
                
            except Exception as e:
                st.error(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
                logger.error(f"Indexing error: {e}")
                logger.error(traceback.format_exc())

def render_status_section():
    """Render current status"""
    st.subheader("ğŸ“Š ç¾åœ¨ã®çŠ¶æ³")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        docs_count = len(st.session_state.documents)
        st.metric("ğŸ“„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ", docs_count, delta=docs_count if docs_count > 0 else None)
    
    with col2:
        chunks_count = len(st.session_state.chunks)
        st.metric("âœ‚ï¸ ãƒãƒ£ãƒ³ã‚¯", chunks_count, delta=chunks_count if chunks_count > 0 else None)
    
    with col3:
        index_status = "âœ… å®Œäº†" if st.session_state.index_ready else "âŒ æœªä½œæˆ"
        st.metric("ğŸš€ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹", index_status)
    
    with col4:
        chain_status = "âœ… æº–å‚™å®Œäº†" if st.session_state.chain else "âŒ æœªæº–å‚™"
        st.metric("ğŸ¤– ãƒã‚§ãƒ¼ãƒ³", chain_status)
    
    # Detailed statistics
    if st.session_state.stats:
        with st.expander("ğŸ“ˆ è©³ç´°çµ±è¨ˆ"):
            st.json(st.session_state.stats, expanded=False)

def main():
    """Main function for the Documents page"""
    st.set_page_config(
        page_title="Documents - Agent RAG Studio",
        page_icon="ğŸ“„",
        layout="wide"
    )
    
    initialize_session_state()
    
    st.title("ğŸ“„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†")
    st.markdown("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€åˆ†å‰²ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã‚’è¡Œã„ã¾ã™")
    
    # Main workflow
    render_upload_section()
    st.markdown("---")
    render_chunking_section()
    st.markdown("---")
    render_indexing_section()
    st.markdown("---")
    render_status_section()
    
    # Clear all button
    if st.button("ğŸ—‘ï¸ å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢", type="secondary"):
        if st.checkbox("æœ¬å½“ã«ã‚¯ãƒªã‚¢ã—ã¾ã™ã‹ï¼Ÿ"):
            st.session_state.documents = []
            st.session_state.chunks = []
            st.session_state.vector_store = None
            st.session_state.retriever = None
            st.session_state.chain = None
            st.session_state.index_ready = False
            st.session_state.stats = {}
            st.success("å…¨ãƒ‡ãƒ¼ã‚¿ãŒã‚¯ãƒªã‚¢ã•ã‚Œã¾ã—ãŸ")
            st.rerun()

if __name__ == "__main__":
    main()
